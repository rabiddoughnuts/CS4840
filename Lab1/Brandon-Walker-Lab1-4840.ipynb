{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e7773d",
   "metadata": {},
   "source": [
    "### CS 4840 Intro Machine Learning - Lab Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb92a",
   "metadata": {},
   "source": [
    "# <center>End-to-End Machine Learning Pipeline: A Linear Regression Problem</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c61210",
   "metadata": {},
   "source": [
    "## <center><font color='red'>This is only for undergraduate students in CS 4840</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0a0d2",
   "metadata": {},
   "source": [
    "### 1. Overview\n",
    "The learning objective of this lab assignment is for students to understand the end-to-end machine learning pipeline, including how to load the data from csv file to DataFrame, how to take a quick look at data structure and statistics, how to visualize the data to gain insights, how to deal with missing features and categorical features, and how to scale feature values. As we use diabetes data as an example, this lab assignment also includes how to build a linear regression model using scikit-learn and gradient descent (PyTorch) to predict the diabetes progression in one year, and how to evaluate the regression results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633487e0",
   "metadata": {},
   "source": [
    "#### Lecture notes. \n",
    "Detailed coverage of these topics can be found in the following:\n",
    "<li>Terms and Principles of Machine Learning</li>\n",
    "<li>Model Training using Gradient Descent</li>\n",
    "<li>Data and Feature Examination</li>\n",
    "<li>Feature Preprocessing</li>\n",
    "\n",
    "#### Code demonstrations. \n",
    "<li>Code 2024-09-09-M-Model Training using Gradient Descent-1.ipynb</li>\n",
    "<li>Code 2024-09-11-W-Gradient Descent Variants.ipynb</li>\n",
    "<li>Code 2024-09-11-W-Training Linear Regression using Scikit-Learn.ipynb</li>\n",
    "<li>Code 2024-09-11-W-Training Linear Regression using PyTorch.ipynb</li>\n",
    "<li>Code 2024-09-16-M-Data and Feature Processing.ipynb</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253216",
   "metadata": {},
   "source": [
    "### 2. Submission\n",
    "You need to submit a detailed lab report with code, running results, and answers to the questions. If you submit <font color='red'>a jupyter notebook (“Firstname-Lastname-4840-Lab1.ipynd”)</font>, please fill in this file directly and place the code, running results, and answers in order for each question. If you submit <font color='red'>a PDF report (“Firstname-Lastname-4840-Lab1.pdf”) with code file (“Firstname-Lastname-4840-Lab1.py”)</font>, please include the screenshots (code and running results) with answers for each question in the report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ac85",
   "metadata": {},
   "source": [
    "### 3. Questions (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bffccc",
   "metadata": {},
   "source": [
    "For this lab assignment, you will be using the `Diabetes dataset` to complete the following tasks and answer the questions. Diabetes dataset has different features and a target label. You will use these features to build a linear regression model to predict the diabetes disease progression one year. First, please place `diabetes.csv` and your notebook/python file in the same directory, and load the data into DataFrame.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98706103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Please place diabetes.csv and your notebook/python file in the same directory; otherwise, change DATA_PATH \n",
    "DATA_PATH = \"\"\n",
    "\n",
    "def load_diabetes_data(diabetes_path=DATA_PATH):\n",
    "    csv_path = os.path.join(diabetes_path, \"diabetes.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "diabetes = load_diabetes_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ab7ee",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 1</font> (3 points):  \n",
    "Please print out the information/statistics of diabetes DataFrame in function `answer_one( )`, and describe: how many records does the diabetes dataset have? Except for the target label `diabetes_progression_one_year`, how many features does the diabetes dataset have? What are these features? Among these features, which feature is non-numerical (categorical) and which feature has missing values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    #Please complete print() using diabetes(DataFrame)'s information API \n",
    "    print( )\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20d931",
   "metadata": {},
   "source": [
    "#### <font color=blue>Answer 1:</font>\n",
    "(Put your answers here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = \"\"\n",
    "\n",
    "def load_diabetes_data(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"diabetes.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "diabetes = load_diabetes_data()\n",
    "\n",
    "def answer_one():\n",
    "    print(diabetes.describe(include='all'))\n",
    "    print(diabetes.all())\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8b73a",
   "metadata": {},
   "source": [
    "The dataset has 441 records, and 10 features. The features are as listed below. Gender is non-numerical and total cholesterol is the only feature with missing values.\n",
    "-  Age\n",
    "-  Gender\n",
    "-  BMI\n",
    "-  Blood Pressure\n",
    "-  Total Serum Cholesterol\n",
    "-  Low Density Lipoproteins\n",
    "-  High Density Lipoproteins\n",
    "-  Total Cholesterol\n",
    "-  Serum Triglycerides\n",
    "-  Blood Sugar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9290d7",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 2</font> (5 points):  \n",
    "Please calculate feature correlation matrix and print out the feature correlation information for `diabetes_progression_one_year` in function `answer_three( )`, and describe: except for `diabetes_progression_one_year` itself, which feature has the strongest correlation with `diabetes_progression_one_year`, and which feature has the weakest correlation with `diabetes_progression_one_year`? Why?   \n",
    "\n",
    "After that, please fill in feature name in the option `x=\" \"` of plot function in `answer_two( )` to plot the data distribution between the strongest/weakest feature and `diabetes_progression_one_year`. Please describe your observations on these two plots: how the data distribution looks like for each plot, and if the data distribution conforms to the obtained feature correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    #Please complete the function using diabetes(DataFrame)'s correlation API\n",
    "    corr_matrix = \n",
    "    #Please print out the feature correlation information for diabetes_progression_one_year from corr_matrix in the descending order\n",
    "    print( )\n",
    "\n",
    "    #First, run the above code and figure out the feature (strongest_feature) that has the strongest correlation with `diabetes_progression_one_year`, \n",
    "    #and the feature (weakest_feature) that has the weakest correlation with `diabetes_progression_one_year`\n",
    "    #Then, set option x=\" \" using the name of strongest_feature \n",
    "    diabetes.plot(kind=\"scatter\", x=\" \", y=\"diabetes_progression_one_year\", alpha=0.3)\n",
    "    plt.axis([0, 45, 0, 360])\n",
    "    \n",
    "    #Please set option x=\" \" using the name of weakest_feature\n",
    "    diabetes.plot(kind=\"scatter\", x=\" \", y=\"diabetes_progression_one_year\", alpha=0.3)\n",
    "    plt.axis([0, 250, 0, 360])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ede74",
   "metadata": {},
   "source": [
    "#### <font color=blue>Answer 2:</font>\n",
    "(Put your answers here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f42b5",
   "metadata": {},
   "source": [
    "My code below is continued directly from code one, so I am not including the \"#include\" sections from question 1\n",
    "\n",
    "The feature with the strongest correlation with Diabetes progression is bmi, and the feature with the weakest correlation is low-density-lipoproteins. The plot for bmi vs diabetes progression wasnt as organized as I expected, but there was just enough of a pattern to be visible where higher bmi related to diabetes progression, the plot for low density lipoproteins looked like a circle, with random dots all over, like a toddler stabbed a pen at paper for a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    corr_matrix = diabetes.corr(method='pearson', numeric_only=True)\n",
    "    print(corr_matrix)\n",
    "\n",
    "    diabetes.plot(kind=\"scatter\", x=\"bmi\", y=\"diabetes_progression_one_year\", alpha=0.3)\n",
    "    plt.axis([0, 45, 0, 360])\n",
    "\n",
    "    diabetes.plot(kind=\"scatter\", x=\"low_density_lipoproteins\", y=\"diabetes_progression_one_year\", alpha=0.3)\n",
    "    plt.axis([0, 250, 0, 360])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "answer_two()\n",
    "\n",
    "diabetes_labels = diabetes[\"diabetes_progression_one_year\"].copy()\n",
    "diabetes_features = diabetes.drop(\"diabetes_progression_one_year\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185db482",
   "metadata": {},
   "source": [
    "***\n",
    "#### Devide the DataFrame into features `diabetes_features` and labels `diabetes_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c576f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_labels = diabetes[\"diabetes_progression_one_year\"].copy() # use diabete_progression_one_year as label\n",
    "diabetes_features = diabetes.drop(\"diabetes_progression_one_year\", axis=1) # drop diabete_progression_one_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f32e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    median_cholesterol = diabetes_features[\"total_cholesterol\"].median()\n",
    "    diabetes_features[\"total_cholesterol\"] = diabetes_features[\"total_cholesterol\"].fillna(median_cholesterol)\n",
    "    print(diabetes_features[diabetes_features.isnull().any(axis=1)].head())\n",
    "\n",
    "answer_three()\n",
    "\n",
    "diabetes_num = diabetes_features.drop(\"gender\", axis=1)\n",
    "\n",
    "diabetes_cat = diabetes_features[[\"gender\"]]\n",
    "print(diabetes_cat[\"gender\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c978095",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 3</font> (3 points):  \n",
    "As `total_cholesterol` has missing values, please use its <font color=red>median</font> number to set those missing feature values in function `answer_three( )`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bf240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    #Please operate on diabetes_features to set the missing \"total_cholesterol\" values using median\n",
    "    median = \n",
    "    diabetes_features.\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2042c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check if there are still records with null feature values\n",
    "#Empty DataFrame means no record with null feature values\n",
    "print(diabetes_features[diabetes_features.isnull().any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfb5fb",
   "metadata": {},
   "source": [
    "***\n",
    "#### Devide features into numerical part `diabetes_num` and categorical part `diabetes_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f41376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes_num only includes the numerical features without gender\n",
    "diabetes_num = diabetes_features.drop(\"gender\", axis=1)\n",
    "\n",
    "#diabetes_cat only includes the categorical feature gender\n",
    "diabetes_cat = diabetes_features[[\"gender\"]]\n",
    "print(diabetes_cat[\"gender\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a197db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    median_cholesterol = diabetes_features[\"total_cholesterol\"].median()\n",
    "    diabetes_features[\"total_cholesterol\"] = diabetes_features[\"total_cholesterol\"].fillna(median_cholesterol)\n",
    "    print(diabetes_features[diabetes_features.isnull().any(axis=1)].head())\n",
    "\n",
    "answer_three()\n",
    "\n",
    "diabetes_num = diabetes_features.drop(\"gender\", axis=1)\n",
    "\n",
    "diabetes_cat = diabetes_features[[\"gender\"]]\n",
    "print(diabetes_cat[\"gender\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74087a8",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 4</font> (3 points):\n",
    "As gender contains categories without order, please convert these categoties into numbers directly using `OrdinalEncoder` in function `answer_four( )`, and print out gender values after conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def answer_four():\n",
    "    ordinal_encoder = \n",
    "    #Please complete the code line using fit_transform API to operate on diabetes_cat\n",
    "    diabetes_cat_encoded = \n",
    "    \n",
    "    return diabetes_cat_encoded\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "diabetes_cat_encoded = answer_four()\n",
    "print(diabetes_cat_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def answer_four():\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    diabetes_cat_encoded = ordinal_encoder.fit_transform(diabetes_cat)\n",
    "\n",
    "    return diabetes_cat_encoded\n",
    "\n",
    "diabetes_cat_encoded = answer_four()\n",
    "print(diabetes_cat_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01ff7e",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 5</font> (3 points):\n",
    "As numerical features have very different scales, please get all the features to have the same scale using `StandardScaler` in function `answer_five( )`, and print out feature values after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd001418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def answer_five():\n",
    "    std_scaler = \n",
    "    #Please complete the code line using fit_transform API to operate on diabetes_num\n",
    "    diabetes_num_scaled = \n",
    "    \n",
    "    return diabetes_num_scaled\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "diabetes_num_scaled = answer_five()\n",
    "print(diabetes_num_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0484b",
   "metadata": {},
   "source": [
    "***\n",
    "#### Concatenate `diabetes_num_scaled` and `diabetes_cat_encoded` into the final features `X` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47795dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diabetes features\n",
    "X = np.concatenate((diabetes_num_scaled, diabetes_cat_encoded), axis=1)\n",
    "\n",
    "#Diabetes labels\n",
    "y = diabetes_labels.to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def answer_five():\n",
    "    std_scaler = StandardScaler()\n",
    "    diabetes_num_scaled = std_scaler.fit_transform(diabetes_num)\n",
    "\n",
    "    return diabetes_num_scaled\n",
    "\n",
    "diabetes_num_scaled = answer_five()\n",
    "print(diabetes_num_scaled)\n",
    "\n",
    "X = np.concatenate((diabetes_num_scaled, diabetes_cat_encoded), axis=1)\n",
    "\n",
    "Y = diabetes_labels.to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13dabd",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 6</font> (5 points):\n",
    "Please use `train_test_split` to split `X` and `y` into training and test sets `(X_train, X_test, y_train, and y_test)` in function `answer_six()`, and describe the shape of `X_train`, `X_test`, `y_train`, and `y_test`, respectively. \n",
    "\n",
    "**Set `random_state=42` and `test_size=0.2` in `train_test_split` to make sure 80% of your dataset is used for training and 20% for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_six():\n",
    "    #Please complete the code line using train_test_split\n",
    "    X_train, X_test, y_train, y_test = \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "X_train, X_test, y_train, y_test = answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c4ed2",
   "metadata": {},
   "source": [
    "#### <font color=blue>Answer 6:</font>\n",
    "(Put your answers here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471bcf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_six():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204f8d7",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 7</font> (10 points):\n",
    "Please first use `LinearRegression` from scikit-learn to build a linear regression model with `X_train` and `y_train` in function `answer_seven( )`, and then evaluate the trained linear regression model by calculating root mean square error (RMSE) and mean absolute error (MAE) between the true labels `y_test` and predictions `y_predict`, and describe the results of RMSE and MAE. \n",
    "\n",
    "According to RMSE and MAE, describe if your linear regression model trained on `X_train` and `y_train` using scikit-learn makes good predictions and explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def answer_seven():\n",
    "    #Please create the model\n",
    "    lin_reg = \n",
    "    \n",
    "    #Please train the model using fit API\n",
    "    lin_reg.\n",
    "\n",
    "    #Make prediction on the X_test using the trained model\n",
    "    y_predict = \n",
    "\n",
    "    #Please calculate root mean square error using root_mean_squared_error API\n",
    "    rmse = \n",
    "\n",
    "    #Please calculate mean absolute error using mean_absolute_error API\n",
    "    mae = \n",
    "    \n",
    "    return rmse, mae\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "rmse_sklearn, mae_sklearn = answer_seven()\n",
    "print(rmse_sklearn, mae_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dc42b",
   "metadata": {},
   "source": [
    "#### <font color=blue>Answer 7:</font>\n",
    "(Put your answers here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393dcd8",
   "metadata": {},
   "source": [
    "My RMSE was 53.64, and my MAE was 42.71. This tells me that my model did not make good predictions, because these are very high values, which indicates high error. These values are not very far apart, which tells me there are not huge outliers to skew the RMSE too much. I believe this model does not make good predictions because of a lack of data, and no weight adjustments yet, but also, I just think the features lacked the strong correlations necessary to make a truly good model, as the strongest correlation wasnt even a .6, and there were only 3 features with above a |.5| correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def answer_seven():\n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    lin_reg.fit(X_train, Y_train)\n",
    "\n",
    "    Y_predict = lin_reg.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(Y_test, Y_predict)\n",
    "\n",
    "    mae = mean_absolute_error(Y_test, Y_predict)\n",
    "\n",
    "    return rmse, mae\n",
    "\n",
    "rmse_sklearn, mae_sklearn = answer_seven()\n",
    "print(rmse_sklearn, mae_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87e385-0b74-481d-bf0d-f33045949b55",
   "metadata": {},
   "source": [
    "***\n",
    "#### Pre-define a set of functions used by PyTorch model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb58a9-368e-47b4-94b5-d6db7ebbfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#Data convertion class\n",
    "class ConvertDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        sample = {'feature': feature, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "#ToTensor function\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label'] \n",
    "        label = np.array(label)\n",
    "        return {'feature': torch.from_numpy(feature).float(),\n",
    "                'label': torch.from_numpy(label).float()}\n",
    "\n",
    "#Training function\n",
    "def train(epoch, model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        X, y = data['feature'], data['label'] \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(X).squeeze()\n",
    "\n",
    "        loss = lossfunction(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(\"epoch (%d): Train loss: %.3f\" % (epoch, train_loss/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7be884-093a-4f10-91eb-eddec3939a18",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 8</font> (3 points):\n",
    "Please choose a batch size of your choice, convert diabetes training data `X_train` and diabetes labels `y_train` into tensors used by PyTorch, and then load the converted training data into Dataloader in function `answer_eight( )`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f89e6-845a-484c-96a2-38114262ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = \n",
    "\n",
    "def answer_eight(b_size, X_train, y_train):\n",
    "    #Please convert X_train and y_train\n",
    "    train_dataset = \n",
    "\n",
    "    #Load the converted training data into DataLoader: pass b_size you choose to the parameter batch_size\n",
    "    train_dataloader = \n",
    "\n",
    "    return train_dataloader\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "train_dataloader = answer_eight(b_size, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 21\n",
    "\n",
    "def answer_eight(b_size, X_train, y_train):\n",
    "    #Please convert X_train and y_train\n",
    "    train_dataset = ConvertDataset(X_train, Y_train, transform=ToTensor())\n",
    "\n",
    "    #Load the converted training data into DataLoader: pass b_size you choose to the parameter batch_size\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "train_dataloader = answer_eight(b_size, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26f015-8ff3-4d93-9265-68c6364bf8d8",
   "metadata": {},
   "source": [
    "***\n",
    "#### <font color=blue>Question 9</font> (15 points):\n",
    "Please first choose epochs, learning rate, and loss function of your choice. In function `answer_nine( )`, create a linear regression class, and then instantiate an object from that class to serve as the model. After that, specify `optimizer` using `Adam`, and then train the model. After the model is trained, calculate root mean square error (RMSE) and mean absolute error (MAE) between the true labels `y_test` and predictions `y_predict`, and describe the results of RMSE and MAE. \n",
    "\n",
    "According to RMSE and MAE, describe if your linear regression model trained on `X_train` and `y_train` using PyTorch makes good predictions and explain why.\n",
    "\n",
    "Also, compare to the results in Question 7, which one is better, and explain the potential reason why this difference happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77faca-8ec9-45b2-8d08-0678c0ce7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =       #Consider the input data is very non-linear, please choose a large epochs that is greater than 1000\n",
    "learning_rate = \n",
    "lossfunction = \n",
    "\n",
    "def answer_nine(train_dataloader):\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            #The first parameter should be the feature dimension: refer to the answer to Question 1 \n",
    "            #The second parameter should be the number of regression output, which is 1\n",
    "            self.fc = \n",
    "\n",
    "        def forward(self, x):\n",
    "            #Define the calculation from x to y\n",
    "            y = \n",
    "            return y\n",
    "\n",
    "    #Instantizte an object from the class as the model\n",
    "    model = \n",
    "    #Define optimizer using Adam\n",
    "    optimizer = \n",
    "\n",
    "    #Train the model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        #Run train() function\n",
    "\n",
    "    #Make prediction on the X_test using the trained model\n",
    "    y_predict = model(torch.FloatTensor(X_test)).detach().numpy()\n",
    "\n",
    "    #Please calculate root mean square error using root_mean_squared_error API\n",
    "    rmse = \n",
    "\n",
    "    #Please calculate mean absolute error using mean_absolute_error API\n",
    "    mae = \n",
    "\n",
    "    return rmse, mae\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "rmse_pytorch, mae_pytorch = answer_nine(train_dataloader)\n",
    "print(rmse_pytorch, mae_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fe8b1-1016-4198-80fd-a4f566c69743",
   "metadata": {},
   "source": [
    "#### <font color=blue>Answer 9</font>:\n",
    "(Put your answers here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba89de",
   "metadata": {},
   "source": [
    "I thought my predictions were bad before, but my values under this system are significantly higher. there is also a larger gap between RMSE and MAE, which means either there was greater outliers than I thought, or something about this process makes the outliers \"weigh\" more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1234\n",
    "learning_rate = 0.05\n",
    "lossfunction = nn.MSELoss()\n",
    "\n",
    "def answer_nine(train_dataloader):\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            # The first parameter should be the feature dimension: refer to the answer to Question 1 \n",
    "            # The second parameter should be the number of regression output, which is 1\n",
    "            self.fc = nn.Linear(X_train.shape[1], 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Define the calculation from x to y\n",
    "            y = self.fc(x)\n",
    "            return y\n",
    "\n",
    "    # Instantiate an object from the class as the model\n",
    "    model = LinearRegression()\n",
    "    # Define optimizer using Adam\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Run train() function\n",
    "        train(epoch, model, train_dataloader, optimizer)\n",
    "\n",
    "    # Make prediction on the X_test using the trained model\n",
    "    y_predict = model(torch.FloatTensor(X_test)).detach().numpy()\n",
    "\n",
    "    # Please calculate root mean square error using root_mean_squared_error API\n",
    "    rmse = np.sqrt(np.mean((Y_test - y_predict) ** 2))\n",
    "\n",
    "    # Please calculate mean absolute error using mean_absolute_error API\n",
    "    mae = np.mean(np.abs(Y_test - y_predict))\n",
    "\n",
    "    return rmse, mae\n",
    "\n",
    "# Run your function in the cell to return the result\n",
    "rmse_pytorch, mae_pytorch = answer_nine(train_dataloader)\n",
    "print(rmse_pytorch, mae_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is my complete code all in one spot so you can run it all at once just in case that is helpful.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = \"\"\n",
    "\n",
    "def load_diabetes_data(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"diabetes.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "diabetes = load_diabetes_data()\n",
    "\n",
    "def answer_one():\n",
    "    print(diabetes.all())\n",
    "    print(diabetes.describe(include='all'))\n",
    "\n",
    "answer_one()\n",
    "\n",
    "def answer_two():\n",
    "    corr_matrix = diabetes.corr(method='pearson', numeric_only=True)\n",
    "    print(corr_matrix)\n",
    "\n",
    "    diabetes.plot(kind=\"scatter\", x=\"bmi\", y=\"diabetes_progression_one_year\", alpha=0.3)\n",
    "    plt.axis([0, 45, 0, 360])\n",
    "\n",
    "    diabetes.plot(kind=\"scatter\", x=\"low_density_lipoproteins\", y=\"diabetes_progression_one_year\", alpha=0.3)\n",
    "    plt.axis([0, 250, 0, 360])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "answer_two()\n",
    "\n",
    "diabetes_labels = diabetes[\"diabetes_progression_one_year\"].copy()\n",
    "diabetes_features = diabetes.drop(\"diabetes_progression_one_year\", axis=1)\n",
    "\n",
    "def answer_three():\n",
    "    median_cholesterol = diabetes_features[\"total_cholesterol\"].median()\n",
    "    diabetes_features[\"total_cholesterol\"] = diabetes_features[\"total_cholesterol\"].fillna(median_cholesterol)\n",
    "    print(diabetes_features[diabetes_features.isnull().any(axis=1)].head())\n",
    "\n",
    "answer_three()\n",
    "\n",
    "diabetes_num = diabetes_features.drop(\"gender\", axis=1)\n",
    "\n",
    "diabetes_cat = diabetes_features[[\"gender\"]]\n",
    "print(diabetes_cat[\"gender\"].value_counts())\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def answer_four():\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    diabetes_cat_encoded = ordinal_encoder.fit_transform(diabetes_cat)\n",
    "\n",
    "    return diabetes_cat_encoded\n",
    "\n",
    "diabetes_cat_encoded = answer_four()\n",
    "print(diabetes_cat_encoded)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def answer_five():\n",
    "    std_scaler = StandardScaler()\n",
    "    diabetes_num_scaled = std_scaler.fit_transform(diabetes_num)\n",
    "\n",
    "    return diabetes_num_scaled\n",
    "\n",
    "diabetes_num_scaled = answer_five()\n",
    "print(diabetes_num_scaled)\n",
    "\n",
    "X = np.concatenate((diabetes_num_scaled, diabetes_cat_encoded), axis=1)\n",
    "\n",
    "Y = diabetes_labels.to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_six():\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = answer_six()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def answer_seven():\n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    lin_reg.fit(X_train, Y_train)\n",
    "\n",
    "    Y_predict = lin_reg.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(Y_test, Y_predict)\n",
    "\n",
    "    mae = mean_absolute_error(Y_test, Y_predict)\n",
    "\n",
    "    return rmse, mae\n",
    "\n",
    "rmse_sklearn, mae_sklearn = answer_seven()\n",
    "print(rmse_sklearn, mae_sklearn)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#Data convertion class\n",
    "class ConvertDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        sample = {'feature': feature, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "#ToTensor function\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label'] \n",
    "        label = np.array(label)\n",
    "        return {'feature': torch.from_numpy(feature).float(),\n",
    "                'label': torch.from_numpy(label).float()}\n",
    "\n",
    "#Training function\n",
    "def train(epoch, model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        X, y = data['feature'], data['label'] \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(X).squeeze()\n",
    "\n",
    "        loss = lossfunction(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(\"epoch (%d): Train loss: %.3f\" % (epoch, train_loss/10000))\n",
    "\n",
    "b_size = 32\n",
    "\n",
    "def answer_eight(b_size, X_train, y_train):\n",
    "    #Please convert X_train and y_train\n",
    "    train_dataset = ConvertDataset(X_train, Y_train, transform=ToTensor())\n",
    "\n",
    "    #Load the converted training data into DataLoader: pass b_size you choose to the parameter batch_size\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader\n",
    "\n",
    "#Run your function in the cell to return the result\n",
    "train_dataloader = answer_eight(b_size, X_train, Y_train)\n",
    "\n",
    "epochs = 1234\n",
    "learning_rate = 0.01\n",
    "lossfunction = nn.MSELoss()\n",
    "\n",
    "def answer_nine(train_dataloader):\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            # The first parameter should be the feature dimension: refer to the answer to Question 1 \n",
    "            # The second parameter should be the number of regression output, which is 1\n",
    "            self.fc = nn.Linear(X_train.shape[1], 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Define the calculation from x to y\n",
    "            y = self.fc(x)\n",
    "            return y\n",
    "\n",
    "    # Instantiate an object from the class as the model\n",
    "    model = LinearRegression()\n",
    "    # Define optimizer using Adam\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Run train() function\n",
    "        train(epoch, model, train_dataloader, optimizer)\n",
    "\n",
    "    # Make prediction on the X_test using the trained model\n",
    "    y_predict = model(torch.FloatTensor(X_test)).detach().numpy()\n",
    "\n",
    "    # Please calculate root mean square error using root_mean_squared_error API\n",
    "    rmse = np.sqrt(np.mean((Y_test - y_predict) ** 2))\n",
    "\n",
    "    # Please calculate mean absolute error using mean_absolute_error API\n",
    "    mae = np.mean(np.abs(Y_test - y_predict))\n",
    "\n",
    "    return rmse, mae\n",
    "\n",
    "# Run your function in the cell to return the result\n",
    "rmse_pytorch, mae_pytorch = answer_nine(train_dataloader)\n",
    "print(rmse_pytorch, mae_pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
