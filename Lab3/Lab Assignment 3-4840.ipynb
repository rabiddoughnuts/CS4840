{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e7773d",
   "metadata": {},
   "source": [
    "### CS 4840 Intro Machine Learning - Lab Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb92a",
   "metadata": {},
   "source": [
    "# <center>Neural Networks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0a0d2",
   "metadata": {},
   "source": [
    "### 1. Overview\n",
    "Neural networks are at very core of deep learning, which are versatile, powerful, and scalable, making them ideal to tackle large and highly complex machine learning tasks. The learning objective of this lab assignment is for students to understand neural networks, including how to train different neural networks with different types of datasets and the impacts of key parameters, how to evaluate their classification performances, and how to compare these results among different neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633487e0",
   "metadata": {},
   "source": [
    "#### Lecture notes. \n",
    "Detailed coverage of these topics can be found in the following:\n",
    "<li>Multi-layer perceptron</li>\n",
    "<li>Convolutional neural network</li>\n",
    "<li>Recurrent neural network</li>\n",
    "\n",
    "#### Code demonstrations.\n",
    "<li>Code 2024-11-04-M-Multi-Layer Perceptron using Keras.ipynb</li>\n",
    "<li>Code 2024-11-13-W-Convolutional Neural Networks using Keras.ipynb</li>\n",
    "<li>Code 2024-11-18-M-Recurrent Neural Networks using Keras.ipynb</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253216",
   "metadata": {},
   "source": [
    "### 2. Submission\n",
    "You need to submit a detailed lab report with code, running results, and answers to the questions. If you submit <font color='red'>a jupyter notebook (“Firstname-Lastname-4840-Lab3.ipynb”)</font>, please fill in this file directly and place the code, running results, and answers in order for each question. If you submit <font color='red'>a PDF report (“Firstname-Lastname-4840-Lab3.pdf”) with code file (“Firstname-Lastname-4840-Lab3.py”)</font>, please include the screenshots (code and running results) with answers for each question in the report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ac85",
   "metadata": {},
   "source": [
    "### 3. Questions (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bffccc",
   "metadata": {},
   "source": [
    "For this lab assignment, you will be using the `CIFAR10` image dataset and `Reuters` text dataset to complete the following tasks and answer the questions.    \n",
    "\n",
    "**<font color='red'>You need to use Keras to build neural networks. As Keras has been integrated into Tensorflow package, please install Tensorflow (version ≥2.0 is required) if you haven't done so yet.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\", \"The version of Tensorflow needs to be ≥2.0\"\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"The version of Tensorflow you installed is ≥2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4353ca6",
   "metadata": {},
   "source": [
    "#### Load and plot the `CIFAR10` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b09a4f",
   "metadata": {},
   "source": [
    "`CIFAR10` is a dataset of 60,000 32x32 color images across 10 classes, commonly used for image classification tasks in computer vision. To avoid excessive runtime and resource usage, all these images are converted to grayscale. Loading `CIFAR10` data may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98706103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Download data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert images to grayscale\n",
    "X_train_gray = tf.image.rgb_to_grayscale(X_train)\n",
    "X_test_gray = tf.image.rgb_to_grayscale(X_test)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = X_train_gray.numpy()\n",
    "X_test = X_test_gray.numpy()\n",
    "\n",
    "# Data preprocessing\n",
    "X_train, X_test = X_train / 255., X_test / 255.\n",
    "y_train, y_test = y_train.astype(np.uint8).squeeze(), y_test.astype(np.uint8).squeeze()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Class names for CIFAR-10\n",
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                 \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Plot the data\n",
    "def plot_digits(instances, labels, images_per_row=5):\n",
    "    for i in range(len(instances)):\n",
    "        idx = i // images_per_row\n",
    "        idy = i % images_per_row \n",
    "        ax[idx, idy].imshow(instances[i].squeeze(), cmap=\"gray\")\n",
    "        ax[idx, idy].set_title(class_names[labels[i]])\n",
    "        ax[idx, idy].axis(\"off\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize=(8, 4))\n",
    "example_images = X_train[:10]\n",
    "example_labels = y_train[:10]\n",
    "plot_digits(example_images, example_labels, images_per_row=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a769f5",
   "metadata": {},
   "source": [
    "#### Question 1 (18 points):  \n",
    "Please train a multi-layer perceptron in function `answer_one( )` using `X_train` and `y_train`. After the neural network is trained, evaluate accuracy, micro F1 score, and macro F1 score using `X_test` and `y_test`.\n",
    "\n",
    "`drop_rate` determines the fraction of neurons that are randomly \"dropped\" (set to zero) during each training iteration when applying Dropout regularization.\n",
    "\n",
    "**Set dropout rate in `keras.layers.Dropout()` as `0.0`, `0.3` and `0.5` respectively to compare the different performance** \n",
    "\n",
    "**All the other model settings are specified in comments** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19561043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "drop_rate =   #Please use 0.0, 0.3, and 0.5, respectively\n",
    "\n",
    "def answer_one(drop_rate):\n",
    "    model = keras.models.Sequential([\n",
    "                                                        #Flatten layer with input shape [32, 32, 1]\n",
    "                                                        #Dense hidden layer, 300 neurons, ReLU\n",
    "                                                        #Dropout layer using drop_rate to address ovefitting\n",
    "                                                        #Dense hidden layer, 100 neurons, ReLU \n",
    "                                                        #Dropout layer using drop_rate to address overfitting\n",
    "                                                        #Dense output layer, 10 neurons, softmax\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "                                                        #Loss function \n",
    "                                                        #Optimization algorithm: adam\n",
    "                                                        #Evaluatuion metrics: accuracy \n",
    "    )\n",
    "    \n",
    "    model.fit(                                          #Use X_train, y_train for training\n",
    "                                                        #epochs, 20\n",
    "                                                        #batch size, 32\n",
    "                                                        #Use X_test, y_test for validation\n",
    "    )\n",
    "    \n",
    "    y_proba =                                           #Calculate prediction proabilities on X_test\n",
    "    y_pred =                                            #Obtain the predicted classes from y_proba\n",
    "    \n",
    "    accuracy =                                          #Calculate accuracy\n",
    "    microf1 =                                           #Calculate micro f1\n",
    "    macrof1 =                                           #Calculate macro f1\n",
    "    \n",
    "    return accuracy, microf1, macrof1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "accuracy_1, microf1_1, macrof1_1 = answer_one(drop_rate)\n",
    "print(accuracy_1, microf1_1, macrof1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f25dc",
   "metadata": {},
   "source": [
    "#### Answer 1:  \n",
    "\n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font> <br>\n",
    "Report the performance by three dropout rate of 0.0, 0.3, and 0.5: <br>\n",
    "<b>`keras.layers.Dropout(0.0)`</b>: Training accuracy (the last epoch) is: ( ), Test accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ) <br>\n",
    "<b>`keras.layers.Dropout(0.3)`</b>: Training accuracy (the last epoch) is: ( ), Test accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ) <br>\n",
    "<b>`keras.layers.Dropout(0.5)`</b>: Training accuracy (the last epoch) is: ( ), Test accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ) \n",
    "\n",
    "Based on the training and test accuracy, and their difference, please summarize the impact of dropout on the model performance: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e374e3",
   "metadata": {},
   "source": [
    "#### Question 2 (16 points):  \n",
    "Please train a convolutional neural network in function `answer_two( )` using `X_train` and `y_train`. After the neural network is trained, evaluate accuracy, micro F1 score, and macro F1 score using `X_test` and `y_test`.\n",
    "\n",
    "**Set training epochs in `model.fit` as `10`** \n",
    "\n",
    "**All the other model settings are specified in comments** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def answer_two():\n",
    "    model = keras.models.Sequential([\n",
    "                                                        #Convolution layer, input shape (32, 32, 1), 32 channels, kernel (3, 3), ReLu\n",
    "                                                        #MaxPooling layer, pooling size (2, 2)\n",
    "                                                        #Convolution layer, 64 channels, kernel size (3, 3), ReLU \n",
    "                                                        #MaxPooling layer, pooling size (2, 2) \n",
    "                                                        #Flatten layer\n",
    "                                                        #Dense output layer, 10 neurons, softmax\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "                                                        #Loss function \n",
    "                                                        #Optimization algorithm: adam\n",
    "                                                        #Evaluatuion metrics: accuracy \n",
    "    )\n",
    "    \n",
    "    model.fit(                                          #Use X_train, y_train for training\n",
    "                                                        #epochs, 10\n",
    "                                                        #batch size, 32\n",
    "                                                        #Use X_test, y_test for validation\n",
    "    )\n",
    "    \n",
    "    y_proba =                                           #Calculate prediction proabilities on X_test\n",
    "    y_pred =                                            #Obtain the predicted classes from y_proba\n",
    "    \n",
    "    accuracy =                                          #Calculate accuracy\n",
    "    microf1 =                                           #Calculate micro f1\n",
    "    macrof1 =                                           #Calculate macro f1\n",
    "    \n",
    "    return accuracy, microf1, macrof1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "accuracy_2, microf1_2, macrof1_2 = answer_two()\n",
    "print(accuracy_2, microf1_2, macrof1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fbf13",
   "metadata": {},
   "source": [
    "#### Answer 2:  \n",
    "\n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font> <br>\n",
    "Test accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( )\n",
    "\n",
    "Based on the best performance of multi-layer perceptron (20 epochs) in Question 1 and the performance of convulotional neural network (10 epochs), please summarize your observation: ( ), and explain why: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889934ea",
   "metadata": {},
   "source": [
    "#### Load and print the `Reuters` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1669c",
   "metadata": {},
   "source": [
    "`Reuters` is a dataset, including a collection of 11,228 newswire articles categorized into 46 topics, widely used for multi-class text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fcaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Download data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=10000)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Class names for Reuters\n",
    "class_names = [\n",
    "    \"cocoa\", \"grain\", \"crude\", \"money-fx\", \"earn\", \"acq\", \"wheat\", \"corn\",\n",
    "    \"dlr\", \"sugar\", \"coffee\", \"gold\", \"veg-oil\", \"jobs\", \"money-supply\",\n",
    "    \"oilseed\", \"earnings\", \"nat-gas\", \"reserves\", \"cotton\", \"housing\", \"gas\",\n",
    "    \"silver\", \"zinc\", \"tin\", \"income\", \"alum\", \"lead\", \"copper\", \"retail\",\n",
    "    \"carcass\", \"potato\", \"livestock\", \"iron-steel\", \"rubber\", \"citrus\",\n",
    "    \"instal-debt\", \"money-market\", \"heatwave\", \"nickel\", \"fuel-oil\", \"sunseed\"\n",
    "]\n",
    "\n",
    "# Setup hyperparameters\n",
    "vocab_size = 10000  # Number of unique words to consider\n",
    "max_len = 50        # Maximum length of each review (padding/truncation)\n",
    "\n",
    "# Filter out-of-vocabulary indices\n",
    "def filter_out_of_vocab_indices(data, vocab_size):\n",
    "    return [[min(word, vocab_size - 1) for word in review] for review in data]\n",
    "\n",
    "X_train = filter_out_of_vocab_indices(X_train, vocab_size)\n",
    "X_test = filter_out_of_vocab_indices(X_test, vocab_size)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Print the data\n",
    "print(X_train[0])\n",
    "print(y_train[0], \"-->\", class_names[y_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8525cb",
   "metadata": {},
   "source": [
    "#### Question 3 (16 points):  \n",
    "Please train a recurrent neural network in function `answer_three( )` using `X_train` and `y_train`. After the neural network is trained, evaluate accuracy, micro F1 score, and macro F1 score using `X_test` and `y_test`.\n",
    "\n",
    "**Set training epochs in `model.fit` as `10`** \n",
    "\n",
    "**All the other model settings are specified in comments** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def answer_three():\n",
    "    model = keras.models.Sequential([\n",
    "                                                        #Embedding layer, input_dim (vocab_size), output_dim (32), input_length (max_len)    \n",
    "                                                        #RNN layer, hidden size 64, dropout rate 0.3, ReLU\n",
    "                                                        #Dense output layer, 46 neurons, softmax\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "                                                        #Loss function \n",
    "                                                        #Optimization algorithm: adam\n",
    "                                                        #Evaluatuion metrics: accuracy \n",
    "    )\n",
    "    \n",
    "    model.fit(                                          #Use X_train, y_train for training\n",
    "                                                        #epochs, 10\n",
    "                                                        #batch size, 32\n",
    "                                                        #Use X_test, y_test for validation\n",
    "    )\n",
    "    \n",
    "    y_proba =                                           #Calculate prediction proabilities on X_test\n",
    "    y_pred =                                            #Obtain the predicted classes from y_proba\n",
    "    \n",
    "    accuracy =                                          #Calculate accuracy\n",
    "    microf1 =                                           #Calculate micro f1\n",
    "    macrof1 =                                           #Calculate macro f1\n",
    "    \n",
    "    return accuracy, microf1, macrof1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "accuracy_3, microf1_3, macrof1_3 = answer_three()\n",
    "print(accuracy_3, microf1_3, macrof1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2bea5",
   "metadata": {},
   "source": [
    "#### Answer 3:  \n",
    "\n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font> <br>\n",
    "Test accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( )\n",
    "\n",
    "Based on the performance of recurrent neural network on `Reuters` dataset with 46 classes, please summarize your observation: ( ), and share your thoughts for further improving its performance: ( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
