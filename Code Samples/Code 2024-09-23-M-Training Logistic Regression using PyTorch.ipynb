{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69762c2a",
   "metadata": {},
   "source": [
    "# Train a logistic regression for classification using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3092b-a596-429e-906c-463d167a170b",
   "metadata": {},
   "source": [
    "#### Generate the dataset: 1-dimensional feature vector and 10,000 training samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf74970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'target',\n",
       " 'frame',\n",
       " 'target_names',\n",
       " 'DESCR',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'data_module']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b1f482-f82d-49b4-ae79-e04beec08fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b545164-a533-4d4e-b052-ba4e2e39406d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b542e79-ae78-447a-9f41-0bd72b0d84f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c2dfd-6f35-4141-be8e-04ce0ab43ac3",
   "metadata": {},
   "source": [
    "#### Convert the dataset into Tensor used by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9413217-c442-4042-99a7-695ef9591f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvertDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        sample = {'feature': feature, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        feature, label = sample['feature'], sample['label'] \n",
    "        label = np.array(label)\n",
    "        return {'feature': torch.from_numpy(feature).float(),\n",
    "                'label': torch.from_numpy(label).long()}\n",
    "    \n",
    "#Convert training data\n",
    "train_dataset = ConvertDataset(iris[\"data\"],\n",
    "                               iris[\"target\"],\n",
    "                               transform=transforms.Compose([\n",
    "                                   ToTensor()\n",
    "                               ]))\n",
    "\n",
    "#Load the converted training data into train_dataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db34c974-ffc6-4761-8958-75a9fa54b2d6",
   "metadata": {},
   "source": [
    "#### Use PyTorch to build a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6859d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logisticegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Logisticegression, self).__init__()\n",
    "        self.fc = nn.Linear(4, 3) #The first \"4\" specifies that the feature dimension is 4, and the second \"3\" specifies that this is 3-class classification\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.fc(x) #The output is a 3-dimentional vector: each presenting a prability for the corresponding class\n",
    "        y = self.softmax(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2414f-bb83-4f91-8454-6198295d1eb1",
   "metadata": {},
   "source": [
    "#### Set up some hyperparameters: use mean squared loss, mini-batch with Adam optimizer, and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae42f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisticegression(\n",
      "  (fc): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "lossfunction = nn.CrossEntropyLoss() #Cross entropy loss\n",
    "\n",
    "model = Logisticegression()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) #Using Adam optimizer\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda9e4d-fdd3-4779-bb3c-ceed2b573b22",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd76d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1): Train accuracy: 0.3800, loss: 0.133\n",
      "epoch (2): Train accuracy: 0.5333, loss: 0.123\n",
      "epoch (3): Train accuracy: 0.6667, loss: 0.116\n",
      "epoch (4): Train accuracy: 0.6667, loss: 0.111\n",
      "epoch (5): Train accuracy: 0.6867, loss: 0.108\n",
      "epoch (6): Train accuracy: 0.9000, loss: 0.106\n",
      "epoch (7): Train accuracy: 0.6933, loss: 0.104\n",
      "epoch (8): Train accuracy: 0.8733, loss: 0.102\n",
      "epoch (9): Train accuracy: 0.8067, loss: 0.101\n",
      "epoch (10): Train accuracy: 0.9067, loss: 0.100\n",
      "epoch (11): Train accuracy: 0.8067, loss: 0.099\n",
      "epoch (12): Train accuracy: 0.9533, loss: 0.098\n",
      "epoch (13): Train accuracy: 0.9000, loss: 0.098\n",
      "epoch (14): Train accuracy: 0.9067, loss: 0.097\n",
      "epoch (15): Train accuracy: 0.9400, loss: 0.096\n",
      "epoch (16): Train accuracy: 0.9067, loss: 0.095\n",
      "epoch (17): Train accuracy: 0.9467, loss: 0.095\n",
      "epoch (18): Train accuracy: 0.9400, loss: 0.094\n",
      "epoch (19): Train accuracy: 0.9600, loss: 0.094\n",
      "epoch (20): Train accuracy: 0.9000, loss: 0.094\n",
      "epoch (21): Train accuracy: 0.9400, loss: 0.093\n",
      "epoch (22): Train accuracy: 0.9400, loss: 0.092\n",
      "epoch (23): Train accuracy: 0.9733, loss: 0.092\n",
      "epoch (24): Train accuracy: 0.9667, loss: 0.091\n",
      "epoch (25): Train accuracy: 0.9800, loss: 0.091\n",
      "epoch (26): Train accuracy: 0.9467, loss: 0.090\n",
      "epoch (27): Train accuracy: 0.9733, loss: 0.090\n",
      "epoch (28): Train accuracy: 0.9733, loss: 0.090\n",
      "epoch (29): Train accuracy: 0.9733, loss: 0.089\n",
      "epoch (30): Train accuracy: 0.9667, loss: 0.089\n",
      "epoch (31): Train accuracy: 0.9667, loss: 0.088\n",
      "epoch (32): Train accuracy: 0.9600, loss: 0.088\n",
      "epoch (33): Train accuracy: 0.9733, loss: 0.088\n",
      "epoch (34): Train accuracy: 0.9667, loss: 0.087\n",
      "epoch (35): Train accuracy: 0.9600, loss: 0.087\n",
      "epoch (36): Train accuracy: 0.9733, loss: 0.087\n",
      "epoch (37): Train accuracy: 0.9467, loss: 0.088\n",
      "epoch (38): Train accuracy: 0.9667, loss: 0.087\n",
      "epoch (39): Train accuracy: 0.9733, loss: 0.086\n",
      "epoch (40): Train accuracy: 0.9667, loss: 0.086\n",
      "epoch (41): Train accuracy: 0.9667, loss: 0.086\n",
      "epoch (42): Train accuracy: 0.9667, loss: 0.086\n",
      "epoch (43): Train accuracy: 0.9667, loss: 0.085\n",
      "epoch (44): Train accuracy: 0.9667, loss: 0.085\n",
      "epoch (45): Train accuracy: 0.9667, loss: 0.085\n",
      "epoch (46): Train accuracy: 0.9667, loss: 0.085\n",
      "epoch (47): Train accuracy: 0.9667, loss: 0.085\n",
      "epoch (48): Train accuracy: 0.9667, loss: 0.084\n",
      "epoch (49): Train accuracy: 0.9733, loss: 0.084\n",
      "epoch (50): Train accuracy: 0.9733, loss: 0.084\n"
     ]
    }
   ],
   "source": [
    "#Define the training function\n",
    "def train(epoch, model, train_dataloader, optimizer, lossfunction):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_total, train_correct = 0.0, 0.0 \n",
    "    \n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        X, y = data['feature'], data['label'] \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(X)\n",
    "\n",
    "        loss = lossfunction(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        train_loss += loss.item()\n",
    "        _, train_predicted = torch.max(predictions.data, 1)\n",
    "        train_total += y.size(0)\n",
    "        train_correct += (train_predicted == y).sum().item()\n",
    "\n",
    "    print(\"epoch (%d): Train accuracy: %.4f, loss: %.3f\" % (epoch, train_correct/train_total, train_loss/train_total))\n",
    "    \n",
    "    \n",
    "#Train the model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, model, train_dataloader, optimizer, lossfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138920e-c2a7-45a6-a948-15e08abdf28d",
   "metadata": {},
   "source": [
    "#### Using the trained model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09e7e98d-7f84-46b1-90d8-c1d98af36967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.8840e-01, 1.1601e-02, 1.6928e-06]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "predicted_probability= model(torch.Tensor([[5.1, 3.5, 1.4, 0.2]]))\n",
    "print(predicted_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c4d68af-7818-40b8-ace7-c75bb5bcbe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "setosa\n"
     ]
    }
   ],
   "source": [
    "_, predicted_label = torch.max(predicted_probability.data, 1)\n",
    "print(predicted_label)\n",
    "print(iris.target_names[predicted_label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
