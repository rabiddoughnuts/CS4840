{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e7773d",
   "metadata": {},
   "source": [
    "### CS 4840 Intro Machine Learning - Lab Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb92a",
   "metadata": {},
   "source": [
    "# <center>Building and Analyzing Classification Models</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0690eff",
   "metadata": {},
   "source": [
    "## <center><font color='red'>This is only for undergraduate students in CS 4840</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0a0d2",
   "metadata": {},
   "source": [
    "### 1. Overview\n",
    "The learning objective of this lab assignment is for students to understand different classification models, including how to apply logistic regression, k-nearest neighbors, decision tree, and ensemble learning and random forest with the impacts of key parameters, how to evaluate their classification performances, and how to compare these results across different classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633487e0",
   "metadata": {},
   "source": [
    "#### Lecture notes. \n",
    "Detailed coverage of these topics can be found in the following:\n",
    "<li>Logistic Regression</li>\n",
    "<li>Evaluation Metrics for Classification</li>\n",
    "<li>k-Nearest Neighbors</li>\n",
    "<li>Decision Tree</li>\n",
    "<li>Ensemble Learning and Random Forest</li>\n",
    "\n",
    "#### Code demonstrations.\n",
    "<li>Code 2024-09-23-M-Training Logistic Regression using Scikit-Learn.ipynb</li>\n",
    "<li>Code 2024-09-25-W-Evaluation Metrics for Classification-Scikit-Learn.ipynb</li>\n",
    "<li>Code 2024-10-02-W-k-Nearest Neighbors.ipynb</li>\n",
    "<li>Code 2024-10-09-W-Decision Tree.ipynb</li>\n",
    "<li>Code 2024-10-21-M-Ensemble Learning and Random Forest.ipynb</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253216",
   "metadata": {},
   "source": [
    "### 2. Submission\n",
    "You need to submit a detailed lab report with code, running results, and answers to the questions. If you submit <font color='red'>a jupyter notebook (“Firstname-Lastname-4840-Lab2.ipynd”)</font>, please fill in this file directly and place the code, running results, and answers in order for each question. If you submit <font color='red'>a PDF report (“Firstname-Lastname-4840-Lab2.pdf”) with code file (“Firstname-Lastname-4840-Lab2.py”)</font>, please include the screenshots (code and running results) with answers for each question in the report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ac85",
   "metadata": {},
   "source": [
    "### 3. Questions (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bffccc",
   "metadata": {},
   "source": [
    "For this lab assignment, you will be using the `housing` dataset to complete the following tasks and answer the questions. The housing dataset is the California Housing Prices dataset based on data from the 1990 California census. You will use these features to build classification models to predict the `ocean proximity` of a house. First, please place `housing.csv` and your notebook/python file in the same directory, and load and preprocess the data.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4353ca6",
   "metadata": {},
   "source": [
    "#### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98706103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 12)\n",
      "(4128, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146262/3390959599.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  housing_features[\"total_bedrooms\"].fillna(median, inplace=True)\n",
      "/tmp/ipykernel_146262/3390959599.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  housing_features[\"bedrooms_per_room\"].fillna(median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Please place housing.csv and your notebook/python file in the same directory; otherwise, change DATA_PATH \n",
    "DATA_PATH = \"\"\n",
    "\n",
    "def load_housing_data(housing_path=DATA_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "#Add three useful features\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "\n",
    "#Divide the data frame into features and labels\n",
    "housing_labels = housing[\"ocean_proximity\"].copy() # use ocean_proximity as classification label\n",
    "housing_features = housing.drop(\"ocean_proximity\", axis=1) # use colums other than ocean_proximity as features\n",
    "\n",
    "#Preprocessing the missing feature values\n",
    "median = housing_features[\"total_bedrooms\"].median()\n",
    "housing_features[\"total_bedrooms\"].fillna(median, inplace=True) \n",
    "median = housing_features[\"bedrooms_per_room\"].median()\n",
    "housing_features[\"bedrooms_per_room\"].fillna(median, inplace=True)\n",
    "\n",
    "#Scale the features\n",
    "std_scaler  = StandardScaler()\n",
    "housing_features_scaled = std_scaler.fit_transform(housing_features)\n",
    "\n",
    "#Final housing features X\n",
    "X = housing_features_scaled\n",
    "\n",
    "#Binary labels - 0: INLAND; 1: CLOSE TO OCEAN\n",
    "y_binary = (housing_labels != 1).astype(int)\n",
    "#Multi-class labels - 0: <1H OCEAN; 1: INLAND; 2: NEAR OCEAN; 3: NEAR BAY\n",
    "y_multi = housing_labels.astype(int)\n",
    "\n",
    "#Data splits for binary classification\n",
    "X_train_bi, X_test_bi, y_train_bi, y_test_bi = train_test_split(X, y_binary, test_size=0.20, random_state=42)\n",
    "\n",
    "#Data splits for multi-class classification\n",
    "X_train_mu, X_test_mu, y_train_mu, y_test_mu = train_test_split(X, y_multi, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X_train_bi.shape)\n",
    "print(X_test_bi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e92572",
   "metadata": {},
   "source": [
    "<font color='red'><b>About the data used in this assignment: </b></font><br>\n",
    "**All the binary classification models are trained on `X_train_bi`, `y_train_bi`, and evaluated on `X_test_bi`, `y_test_bi`.**<br>\n",
    "**All the multi-class classification models are trained on `X_train_mu`, `y_train_mu`, and evaluated on `X_test_mu`, `y_test_mu`.**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ab7ee",
   "metadata": {},
   "source": [
    "#### Question 1 (4 points):  \n",
    "Please use features `X_train_bi` and binary labels `y_train_bi` to train a logistic regression binary classification model in function `answer_one( )`. After the model is trained, use `X_test_bi` and `y_test_bi` to evaluate the performance, including accuracy and F1 score.\n",
    "\n",
    "**Choose your own `solver` and set `random_state=42` in `LogisticRegression`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5a7ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9600290697674418\n",
      "0.9710068529256721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def answer_one():\n",
    "    # Initialize the logistic regression model with a solver and random state\n",
    "    binary_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    binary_reg.fit(X_train_bi, y_train_bi)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_bi = binary_reg.predict(X_test_bi)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    binary_reg_accuracy = accuracy_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    binary_reg_f1 = f1_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    return binary_reg_accuracy, binary_reg_f1\n",
    "\n",
    "# Run your function in the cell to return the results\n",
    "accuracy_1, f1_1 = answer_one()\n",
    "\n",
    "print(accuracy_1)\n",
    "print(f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d7e96",
   "metadata": {},
   "source": [
    "#### Answer 1:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "Accuracy is: (0.96) <br>\n",
    "F1 score is: (0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28237ee",
   "metadata": {},
   "source": [
    "#### Question 2 (4 points):  \n",
    "Please use features `X_train_mu` and multi-class labels `y_train_mu` to train a softmax regression multi-class classification model in function `answer_two( )`. After the model is trained, use `X_test_mu` and `y_test_mu` to evaluate the performance, including accuracy, micro F1 score, and macro F1 score.\n",
    "\n",
    "**Set `solver=\"newton-cg\"` to guarantee the convergence of train loss minimization and set `random_state=42` in `LogisticRegression`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2312b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7974806201550387\n",
      "0.7974806201550387\n",
      "0.6847642281014538\n"
     ]
    }
   ],
   "source": [
    "def answer_two():\n",
    "    # Initialize the logistic regression model with solver 'newton-cg' and random state\n",
    "    multi_reg = LogisticRegression(solver='newton-cg', random_state=42)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    multi_reg.fit(X_train_mu, y_train_mu)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_mu = multi_reg.predict(X_test_mu)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    multi_reg_accuracy = accuracy_score(y_test_mu, y_pred_mu)\n",
    "    \n",
    "    # Calculate micro F1 score\n",
    "    multi_reg_microf1 = f1_score(y_test_mu, y_pred_mu, average='micro')\n",
    "    \n",
    "    # Calculate macro F1 score\n",
    "    multi_reg_macrof1 = f1_score(y_test_mu, y_pred_mu, average='macro')\n",
    "    \n",
    "    return multi_reg_accuracy, multi_reg_microf1, multi_reg_macrof1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "accuracy_2, microf1_2, macrof1_2 = answer_two()\n",
    "print(accuracy_2)\n",
    "print(microf1_2)\n",
    "print(macrof1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750a8ae",
   "metadata": {},
   "source": [
    "#### Answer 2:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "Accuracy is: (0.7975) <br>\n",
    "Micro f1 score is: (0.7975) <br>\n",
    "Macro f1 score is: (0.6848)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9290d7",
   "metadata": {},
   "source": [
    "#### Question 3 (5 points):  \n",
    "Please use features `X_train_bi` and binary labels `y_train_bi` to train a k-nearest neighbors binary classification model in function `answer_three( )`. After the model is trained, use `X_test_bi` and `y_test_bi` to evaluate the performance, including accuracy and F1 score.\n",
    "\n",
    "**Set the option `n_neighbors=` in `KNeighborsClassifier` using `1`, `3`, `5`, `7`, and `9` respectively to find an optimal value `k`**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745c3f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0.9256298449612403, np.float64(0.9456155890168291)),\n",
       " 3: (0.9367732558139535, np.float64(0.9543307086614173)),\n",
       " 5: (0.935077519379845, np.float64(0.9533101045296167)),\n",
       " 7: (0.9367732558139535, np.float64(0.9546165884194053)),\n",
       " 9: (0.9358042635658915, np.float64(0.9539530842745438))}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Please use 1, 3, 5, 7, 9\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "def answer_three(k):\n",
    "    # Initialize the k-nearest neighbors model with k neighbors\n",
    "    binary_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    binary_knn.fit(X_train_bi, y_train_bi)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_bi = binary_knn.predict(X_test_bi)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    binary_knn_accuracy = accuracy_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    binary_knn_f1 = f1_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    return binary_knn_accuracy, binary_knn_f1\n",
    "\n",
    "# Run your function in the cell to return the results for each k\n",
    "results = {}\n",
    "for k in k_values:\n",
    "    accuracy, f1 = answer_three(k)\n",
    "    results[k] = (accuracy, f1)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191991b",
   "metadata": {},
   "source": [
    "#### Answer 3: \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "<b>When k = 1</b>, accuracy is: (0.9256)<br>\n",
    "<b>When k = 3</b>, accuracy is: (0.9368)<br>\n",
    "<b>When k = 5</b>, accuracy is: (0.9351)<br>\n",
    "<b>When k = 7</b>, accuracy is: (0.9368)<br>\n",
    "<b>When k = 9</b>, accuracy is: (0.9358)<br>\n",
    "<b>Optimal k (`n_neighbors`) is</b>: (7), accuracy is: (0.9368), F1 score is: (0.9546)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a769f5",
   "metadata": {},
   "source": [
    "#### Question 4 (7 points):  \n",
    "Please use features `X_train_mu` and multi-class labels `y_train_mu` to train a k-nearest neighbors multi-class classification model in function `answer_four( )`. After the model is trained, use `X_test_mu` and `y_test_mu` to evaluate the performance, including accuracy, micro F1 score, macro F1 score, loading time, and prediction time.\n",
    "\n",
    "**Set `n_neighbors=` in `KNeighborsClassifier` using the optimal `k` in Question 3 and set the option `algorithm=` using `'brute'`, `'kd_tree'`, and `'ball_tree'` respectively to compare the different time used**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19561043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brute': (0.8078972868217055,\n",
       "  np.float64(0.8078972868217055),\n",
       "  np.float64(0.7445180350580481),\n",
       "  0.001486063003540039,\n",
       "  0.1413097381591797),\n",
       " 'kd_tree': (0.8078972868217055,\n",
       "  np.float64(0.8078972868217055),\n",
       "  np.float64(0.7445180350580481),\n",
       "  0.015799999237060547,\n",
       "  0.2689788341522217),\n",
       " 'ball_tree': (0.8078972868217055,\n",
       "  np.float64(0.8078972868217055),\n",
       "  np.float64(0.7445180350580481),\n",
       "  0.008485555648803711,\n",
       "  0.4559965133666992)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Please use the optimal k in Question 3\n",
    "k = 7\n",
    "\n",
    "#Please use 'brute', 'kd_tree', and 'ball_tree', respectively  \n",
    "alg = ['brute', 'kd_tree', 'ball_tree']\n",
    "\n",
    "def answer_four(k, alg):\n",
    "    # Add a time checkpoint here\n",
    "    time1 = time.time()\n",
    "    \n",
    "    # Initialize the k-nearest neighbors model with k neighbors and specified algorithm\n",
    "    multi_knn = KNeighborsClassifier(n_neighbors=k, algorithm=alg)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    multi_knn.fit(X_train_mu, y_train_mu)\n",
    "    \n",
    "    # Add a time checkpoint here\n",
    "    time2 = time.time()\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_mu = multi_knn.predict(X_test_mu)\n",
    "    \n",
    "    # Add a time checkpoint here\n",
    "    time3 = time.time()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    multi_knn_accuracy = accuracy_score(y_test_mu, y_pred_mu)\n",
    "    \n",
    "    # Calculate micro F1 score\n",
    "    multi_knn_microf1 = f1_score(y_test_mu, y_pred_mu, average='micro')\n",
    "    \n",
    "    # Calculate macro F1 score\n",
    "    multi_knn_macrof1 = f1_score(y_test_mu, y_pred_mu, average='macro')\n",
    "    \n",
    "    # Time used for data loading\n",
    "    multi_knn_loadtime = time2 - time1\n",
    "    \n",
    "    # Time used for prediction\n",
    "    multi_knn_predictiontime = time3 - time2\n",
    "    \n",
    "    return multi_knn_accuracy, multi_knn_microf1, multi_knn_macrof1, multi_knn_loadtime, multi_knn_predictiontime\n",
    "\n",
    "# Run your function in the cell to return the results for each algorithm\n",
    "results = {}\n",
    "for a in alg:\n",
    "    accuracy, microf1, macrof1, loadtime, predictiontime = answer_four(k, a)\n",
    "    results[a] = (accuracy, microf1, macrof1, loadtime, predictiontime)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f25dc",
   "metadata": {},
   "source": [
    "#### Answer 4:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "<b>Brute force: </b> data loading time is: (0.0010), prediction time is: (0.1635), accuracy is: (0.8079), micro f1 score is: (0.8079), macro f1 score is: (0.7445) <br>\n",
    "<b>K-d tree: </b> data loading time is: (0.0187), prediction time is: (0.3382), accuracy is: (0.8079), micro f1 score is: (0.8079), macro f1 score is: (0.7445) <br>\n",
    "<b>Ball tree: </b> data loading time is: (0.0098), prediction time is: (0.4452), accuracy is: (0.8079), micro f1 score is: (0.8079), macro f1 score is: (0.7445) <br>\n",
    "Summarize your observations about the time used by these searching algorithms: (in this instance, brute force loaded the fastest, and predicted the fastest, I suspect with a larger data pool that might change) and observations about the classification performance: (They all had the exact same performance)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c978095",
   "metadata": {},
   "source": [
    "#### Question 5 (7 points):  \n",
    "Please use features `X_train_bi` and binary labels `y_train_bi` to train a decision tree binary classification model in function `answer_five( )`. After the model is trained, use `X_test_bi` and `y_test_bi` to evaluate the performance, including accuracy and F1 score.\n",
    "\n",
    "**Set `random_state=42` and `criterion='gini'` in `DecisionTreeClassifier`, and set `max_depth=` using `2`, `5`, and `10` respectively to compare different performance** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2bf240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: (0.8604651162790697, np.float64(0.9007238883143743)),\n",
       " 5: (0.9367732558139535, np.float64(0.9545850008700192)),\n",
       " 10: (0.9762596899224806, np.float64(0.9826179496275275))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Please use 2, 5, 10\n",
    "depth = [2, 5, 10]\n",
    "\n",
    "def answer_five(d):\n",
    "    # Initialize the decision tree model with specified max depth, criterion 'gini', and random state\n",
    "    binary_dt = DecisionTreeClassifier(max_depth=d, criterion='gini', random_state=42)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    binary_dt.fit(X_train_bi, y_train_bi)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_bi = binary_dt.predict(X_test_bi)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    binary_dt_accuracy = accuracy_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    binary_dt_f1 = f1_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    return binary_dt_accuracy, binary_dt_f1\n",
    "\n",
    "# Run your function in the cell to return the results for each max depth\n",
    "results = {}\n",
    "for d in depth:\n",
    "    accuracy, f1 = answer_five(d)\n",
    "    results[d] = (accuracy, f1)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c2a70",
   "metadata": {},
   "source": [
    "#### Answer 5:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "<b>When d = 2: </b> accuracy is: (0.8605), and f1 score is: (0.9001) <br> \n",
    "<b>When d = 5: </b> accuracy is: (0.9368), and f1 score is: (0.9546) <br> \n",
    "<b>When d = 10: </b> accuracy is: (0.9763), and f1 score is: (0.9826) <br>\n",
    "Summarize your observations about the performance derived by these different `max_depth`: (More depth seems to correlate to better accuracy and f1 score, for this specific data, though with added computation cost)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74087a8",
   "metadata": {},
   "source": [
    "#### Question 6 (7 points):\n",
    "Please use features `X_train_mu` and multi-class labels `y_train_mu` to train a decision tree multi-class classification model in function `answer_six( )`. After the model is trained, use `X_test_mu` and `y_test_mu` to evaluate the performance, including accuracy, micro F1 score, and macro F1 score.\n",
    "\n",
    "**Set `max_depth=5` and `random_state=42` in `DecisionTreeClassifier` and set `criterion=` using `'gini'` and `'entropy'` respectively to compare different performance**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38e6ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gini': (0.8783914728682171,\n",
       "  np.float64(0.8783914728682171),\n",
       "  np.float64(0.8446278025347744)),\n",
       " 'entropy': (0.8800872093023255,\n",
       "  np.float64(0.8800872093023255),\n",
       "  np.float64(0.864962365347806))}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please use 'gini' and 'entropy' respectively\n",
    "criteria = ['gini', 'entropy']\n",
    "\n",
    "def answer_six(c):\n",
    "    # Initialize the decision tree model with specified criterion, max depth 5, and random state\n",
    "    multi_dt = DecisionTreeClassifier(criterion=c, max_depth=5, random_state=42)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    multi_dt.fit(X_train_mu, y_train_mu)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_mu = multi_dt.predict(X_test_mu)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    multi_dt_accuracy = accuracy_score(y_test_mu, y_pred_mu)\n",
    "    \n",
    "    # Calculate micro F1 score\n",
    "    multi_dt_microf1 = f1_score(y_test_mu, y_pred_mu, average='micro')\n",
    "    \n",
    "    # Calculate macro F1 score\n",
    "    multi_dt_macrof1 = f1_score(y_test_mu, y_pred_mu, average='macro')\n",
    "    \n",
    "    return multi_dt_accuracy, multi_dt_microf1, multi_dt_macrof1\n",
    "\n",
    "# Run your function in the cell to return the results for each criterion\n",
    "results = {}\n",
    "for c in criteria:\n",
    "    accuracy, microf1, macrof1 = answer_six(c)\n",
    "    results[c] = (accuracy, microf1, macrof1)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b673a0",
   "metadata": {},
   "source": [
    "#### Answer 6:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "<b>When c = 'gini': </b> accuracy is: (0.8784), micro f1 score is: (0.8784), macro f1 score is: (0.8446) <br> \n",
    "<b>When c = 'entropy': </b> accuracy is: (0.8800), micro f1 score is: (0.8800), macro f1 score is: (0.8650) <br> \n",
    "Summarize your observations about the performance derived by these different `criterion`: (The entropy criterion has a higher accuracy and macro f1, likely because it accounts for bias)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13dabd",
   "metadata": {},
   "source": [
    "#### Question 7 (7 points):\n",
    "Please use features `X_train_bi` and binary labels `y_train_bi` to train a binary classification model using AdaBoost ensemble learning in function `answer_seven( )`. After the model is trained, use `X_test_bi` and `y_test_bi` to evaluate the performance, including accuracy and F1 score.\n",
    "\n",
    "**Set the base model as `DecisionTreeClassifier(max_depth=1)`, `n_estimators=100` and `random_state=42` in `AdaBoostClassifier`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac5e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970687984496124\n",
      "0.9786256845080374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def answer_seven():\n",
    "    # Initialize the AdaBoost model with DecisionTreeClassifier as the base estimator\n",
    "    binary_ada = AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1),\n",
    "        n_estimators=100,\n",
    "        algorithm='SAMME',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    binary_ada.fit(X_train_bi, y_train_bi)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_bi = binary_ada.predict(X_test_bi)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    binary_ada_accuracy = accuracy_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    binary_ada_f1 = f1_score(y_test_bi, y_pred_bi)\n",
    "    \n",
    "    return binary_ada_accuracy, binary_ada_f1\n",
    "\n",
    "# Run your function in the cell to return the results\n",
    "accuracy_7, f1_7 = answer_seven()\n",
    "print(accuracy_7)\n",
    "print(f1_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65439330",
   "metadata": {},
   "source": [
    "#### Answer 7:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "Accuracy is: (0.9707) <br>\n",
    "F1 score is: (0.9786) <br>\n",
    "Compared to the classificaion results in Question 5 that builds decision trees with `max_depth=2, 5, 10`, summarize your observations about the performance derived by AdaBoost with `DecisionTreeClassifier(max_depth=1)`: (The results from this model performed almost as well as the classification from question 5 on depth of 10, and performed better than the lower depth versions, but also executed much slower so seemingly heavier computation costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7aa2f",
   "metadata": {},
   "source": [
    "#### Question 8 (7 points):\n",
    "Please use features `X_train_mu` and multi-class labels `y_train_mu` to train a random forest multi-class classification model in function `answer_eight( )`. After the model is trained, use `X_test_mu` and `y_test_mu` to evaluate the performance, including accuracy, micro F1 score, and macro F1 score.\n",
    "\n",
    "**Set `n_estimators=10` and `random_state=42` in `RandomForestClassifier`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e63fd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9457364341085271\n",
      "0.9457364341085271\n",
      "0.9356159265365518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def answer_eight():\n",
    "    # Initialize the random forest model with 10 estimators and random state\n",
    "    multi_rf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    \n",
    "    # Train the model using the training data\n",
    "    multi_rf.fit(X_train_mu, y_train_mu)\n",
    "    \n",
    "    # Predict the labels for the test data\n",
    "    y_pred_mu = multi_rf.predict(X_test_mu)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    multi_rf_accuracy = accuracy_score(y_test_mu, y_pred_mu)\n",
    "    \n",
    "    # Calculate micro F1 score\n",
    "    multi_rf_microf1 = f1_score(y_test_mu, y_pred_mu, average='micro')\n",
    "    \n",
    "    # Calculate macro F1 score\n",
    "    multi_rf_macrof1 = f1_score(y_test_mu, y_pred_mu, average='macro')\n",
    "    \n",
    "    return multi_rf_accuracy, multi_rf_microf1, multi_rf_macrof1\n",
    "\n",
    "# Run your function in the cell to return the results\n",
    "accuracy_8, microf1_8, macrof1_8 = answer_eight()\n",
    "print(accuracy_8)\n",
    "print(microf1_8)\n",
    "print(macrof1_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acef8ca",
   "metadata": {},
   "source": [
    "#### Answer 8:  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "<b>When n_estimators=10: </b> accuracy is: (0.9457), micro f1 score is: (0.9457), macro f1 score is: (0.9356) <br> \n",
    "Compared to the classificaion results in Question 6 that builds a single decision tree, summarize your observations about the performance derived by random forest: (Its accuracy and f1 is worse, which is surprising, but I think maybe it needs a larger dataset or smaller number of estimators as a random forest is training several models on the same amount of data.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4d3cc",
   "metadata": {},
   "source": [
    "#### Question 9 (2 points):\n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "Based on the results from Question 1 to Question 8 (considering different model parameters): <br>\n",
    "The model with best binary classification performance is: (Decision Tree with max depth of 10) <br>\n",
    "The model with worst binary classification performance is: (Decision Tree with max depth of 2) <br>\n",
    "The model with best multi-class classification performance is: (Random Forest) <br>\n",
    "The model with worst multi-class classification performance is: (Softmax Regression)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
